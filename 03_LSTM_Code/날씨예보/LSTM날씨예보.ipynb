{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Author : Byunghyun Ban\n",
        "Date : 2020.07.17.\n",
        "\"\"\"\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "import time\n",
        "import pandas as pd\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# 데이터를 떠먹여 줄 클래스를 제작합니다.\n",
        "class DataReader():\n",
        "    def __init__(self, window_size):\n",
        "        self.headers = []\n",
        "        self.train_X, self.train_Y, self.test_X, self.test_Y = self.read_data(window_size)\n",
        "\n",
        "        # 데이터 읽기가 완료되었습니다.\n",
        "        # 읽어온 데이터의 정보를 출력합니다.\n",
        "        print(\"\\n\\nData Read Done!\")\n",
        "        print(\"Training X Size : \" + str(self.train_X.shape))\n",
        "        print(\"Training Y Size : \" + str(self.train_Y.shape))\n",
        "        print(\"Test X Size : \" + str(self.test_X.shape))\n",
        "        print(\"Test Y Size : \" + str(self.test_Y.shape) + '\\n\\n')\n",
        "\n",
        "    def read_data(self, window_size):\n",
        "        #filename = \"/data\" + os.listdir(\"data\")[0]\n",
        "        filename = \"jena_climate_2009_2016\" + \".csv\"\n",
        "        df = pd.read_csv(\"/content/\" + filename)\n",
        "\n",
        "        data = np.loadtxt(filename, delimiter=\",\", skiprows=1, usecols=(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14))\n",
        "        data = data - np.min(data, axis=0) + 0.0001\n",
        "        data = data / np.max(data, axis=0)\n",
        "        train_data = data[:int(len(data)*0.8)]\n",
        "        test_data = data[int(len(data) * 0.8):]\n",
        "\n",
        "        train_X, train_Y = self.windowing(train_data, window_size)\n",
        "        test_X, test_Y = self.windowing(test_data, window_size)\n",
        "\n",
        "        return train_X, train_Y, test_X, test_Y\n",
        "\n",
        "    def windowing(self, array, window_size):\n",
        "        X = []\n",
        "        Y = []\n",
        "\n",
        "        for i in range(len(array)-window_size*2):\n",
        "            X.append(array[i:i+window_size])\n",
        "            Y.append(array[i+window_size:i + window_size*2])\n",
        "\n",
        "        return np.asarray(X), np.asarray(Y)\n",
        "\n",
        "\n",
        "def draw_graph(prediction, label, history):\n",
        "    X = prediction / np.max(prediction, axis=0)\n",
        "    Y = label / np.max(label, axis=0)\n",
        "\n",
        "    minval = min(np.min(X), np.min(Y))\n",
        "    maxval = max(np.max(X), np.max(Y))\n",
        "\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    plt.title(\"Regression Result\")\n",
        "    plt.xlabel(\"Ground Truth\")\n",
        "    plt.ylabel(\"AI Predict\")\n",
        "    plt.scatter(X, Y)\n",
        "    plt.plot([minval, maxval], [minval, maxval], \"red\")\n",
        "    fig.savefig(\"result.png\")\n",
        "\n",
        "    train_history = history.history[\"loss\"]\n",
        "    validation_history = history.history[\"val_loss\"]\n",
        "    fig = plt.figure(figsize=(8, 8))\n",
        "    plt.title(\"Loss History\")\n",
        "    plt.xlabel(\"EPOCH\")\n",
        "    plt.ylabel(\"LOSS Function\")\n",
        "    plt.plot(train_history, \"red\")\n",
        "    plt.plot(validation_history, 'blue')\n",
        "    fig.savefig(\"train_history.png\")\n"
      ],
      "metadata": {
        "id": "8HbV8eZ3W5mQ"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import data_reader\n",
        "from tensorflow import keras\n",
        "\n",
        "# 몇 에포크 만큼 학습을 시킬 것인지 결정합니다.\n",
        "EPOCHS = 2  # 예제 기본값은 50입니다.\n",
        "\n",
        "# 데이터를 읽어옵니다.\n",
        "dr = DataReader(12)\n",
        "\n",
        "# 인공신경망을 제작합니다.\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Bidirectional(keras.layers.LSTM(64, return_sequences=True)),\n",
        "    keras.layers.Dense(32),\n",
        "    keras.layers.Dense(14),\n",
        "])\n",
        "\n",
        "# 인공신경망을 컴파일합니다.\n",
        "model.compile(optimizer=\"adam\", metrics=[\"mae\"], loss=\"mse\")\n",
        "\n",
        "# 인공신경망을 학습시킵니다.\n",
        "print(\"\\n\\n************ TRAINING START ************ \")\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "history = model.fit(dr.train_X, dr.train_Y, epochs=EPOCHS,\n",
        "                    validation_data=(dr.test_X, dr.test_Y),\n",
        "                    callbacks=[early_stop])\n",
        "\n",
        "# 학습 결과를 그래프로 출력합니다.\n",
        "draw_graph(model(dr.test_X[:200]), dr.test_Y[:200], history)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nX9af2_zQEZl",
        "outputId": "4c997c15-5928-4031-88af-8071dba096a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Data Read Done!\n",
            "Training X Size : (336400, 12, 14)\n",
            "Training Y Size : (336400, 12, 14)\n",
            "Test X Size : (84083, 12, 14)\n",
            "Test Y Size : (84083, 12, 14)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "************ TRAINING START ************ \n",
            "Epoch 1/2\n",
            " 9118/10513 [=========================>....] - ETA: 23s - loss: 0.0044 - mae: 0.0343"
          ]
        }
      ]
    }
  ]
}